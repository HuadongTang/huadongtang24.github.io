<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width">
    <style type="text/css">
        .container {
            zoom: 1;
            margin-left: auto;
            margin-right: auto;
            vertical-align: middle;
            text-align: left;
            width: 100%;
            max-width: 800px;
        }
        .content {
            margin-bottom: -10px;
            display: inline-block;
            display*: inline;
            width: 100%;
        }
        a {
          color: #03c;
          text-decoration: none;
          transition: 0.3s all cubic-bezier(0.42, 0, 0.57, 1.96);
        }
    
        a:focus,
        a:hover{
          color: rgb(252, 76, 122);
          border-color: rgb(252, 76, 122);
        }
    </style>
    <title>Shaoshuai Shi's Homepage</title>
    <link rel="icon" href="../content/images/icon.png">
  </head>
  <body>
    <div class="container">
        <table width="100%" align="center" border="0">
<tr>
    <td width="60%" valign="middle">
        <h1 style="margin-top:20px;margin-bottom:36px;">Shaoshuai SHI</h1>
        <p style="font-size:20px; color:#000">
	        Ph.D. Student <br />
	        The Chinese University of Hong Kong
        </p>
        <!-- Email: ssshi [at] ee [dot] cuhk [dot] edu [dot] hk -->
        Email: shaoshuaics [at] gmail [dot] com
        <p>
            <a href="https://scholar.google.com.hk/citations?user=DC9wzBgAAAAJ&amp;hl=zh-CN">[Google Scholar]</a> &nbsp;
            <a href="https://github.com/sshaoshuai">[GitHub]</a> &nbsp;
            <a href="content/pdf/CV_SHIShaoshuai.pdf">[CV]</a>
        </p>
    </td>
    <td width="40%" align="center">
        <img src="content/images/SHI-Shaoshuai-min.png" width="60%" />
    </td>
</tr>
</table>

<h2 id="about-me">About Me</h2>
<hr style="margin-top:-16px;margin-bottom:10px;" />

<p>I am currently a Ph.D. student in <a href="http://mmlab.ie.cuhk.edu.hk/">Multimedia Lab (MMLab)</a>, The Chinese University of Hong Kong (CUHK), supervised by Prof. <a href="http://www.ee.cuhk.edu.hk/~xgwang">Xiaogang Wang</a> and Prof. <a href="http://www.ee.cuhk.edu.hk/~hsli/">Hongsheng Li</a>. Before that, I received my bachelor’s degree from the Computer Science Honor Class of Harbin Institute Technology (HIT) in July 2017. I am about to graduate in the summer of 2021.</p>

<p>My research interests focus on computer vision and deep learning, especially the 3D scene understanding and object detection on the autonomous driving scenarios.</p>

<h2 id="news">News</h2>
<hr style="margin-top:-16px;margin-bottom:10px;" />

<ul>
  <li>Two papers got accepted by ICCV 2021.</li>
  <li>I am awarded the World Artificial Intelligence Conference (WAIC) Rising Star Award, see the <a href="https://www.worldaic.com.cn/newsdetail?uuid=0577d6d5c6f449abb8a4f7426f5d17da">news</a> from <a href="https://www.worldaic.com.cn/">WAIC</a>.</li>
  <li>Two papers got accepted by CVPR 2021.
<!-- * **<span style="color:red;">[NEW]</span>** [2020-06] 
PV-RCNN codes have been released to [[OpenPCDet]](https://github.com/open-mmlab/OpenPCDet). -->
<!-- * **<span style="color:red;">[NEW]</span>**   -->
<!-- * [2020-10] --></li>
  <li>I am awarded <strong>Google PhD Fellowship 2020</strong>, see the <a href="https://ai.googleblog.com/2020/10/announcing-2020-google-phd-fellows.html">news</a> from Google AI Blog. 
<!-- * **<span style="color:red;">[NEW]</span>**   -->
<!-- * [2020-06] --></li>
  <li>Highly optimized PyTorch codebase <a href="https://github.com/open-mmlab/OpenPCDet">OpenPCDet</a> for LiDAR-based 3D scene understanding is released, including the implementation of PV-RCNN, the 1st place method in the KITTI 3D detection leaderboard.
<!-- * **<span style="color:red;">[NEW]</span>**  --></li>
  <li>We win the <span style="color:black;"><strong>1st place among all LiDAR-only methods</strong> </span> on 3D Detection, 3D Tracking, Domain Adaptation three tracks of the <a href="https://waymo.com/open/challenges/">Waymo Open Dataset challenge</a>. See the official <a href="https://blog.waymo.com/2020/07/opendataset-challenge-winners.html">blog post</a> from Waymo.</li>
  <li>Two papers with <span style="color:red;">one oral</span> got accepted by CVPR 2020.</li>
  <li>Our Part-A^2 net got accepted by T-PAMI 2020, code is available at <a href="https://github.com/sshaoshuai/PartA2-Net">PartA2-Net</a>.</li>
  <li>One paper got accepted by ICRA 2020.</li>
  <li>One paper got accepted by CVPR 2019.</li>
  <li>One paper got accepted by ICLR 2019.</li>
  <li>One paper got accepted by ECCV 2018.</li>
</ul>

<script type="text/javascript">
    function hideshow(which){
    if (!document.getElementById)
        return
    if (which.style.display=="block")
        which.style.display="none"
    else
        which.style.display="block"
    }
</script>

<h2 id="codebase">Codebase</h2>
<hr style="margin-top:-16px;margin-bottom:10px;" />

<table class="">
<tr>
    <td width="30%" valign="top">
        <img src="content/images/pcdet_min.png" width="96%" height="100" />
    </td>
    <td width="70%" valign="top">
        <div style="margin-top:0px;margin-bottom:0px;">
        <a href="https://github.com/open-mmlab/OpenPCDet" style="">
            OpenPCDet: An Open-source Toolbox for 3D Object Detection from Point Cloud
        </a>
        <br />
        <font color="#000000">OpenPCDet Development Team </font>
        <br />
        <font style="font-size:15px;"><em>
      <!--       arXiv:1912.13192, Technical Report, 2019
            </em>  -->
            June 2020
            </em> 
        </font>
        <br />
        <a href="https://github.com/open-mmlab/OpenPCDet" style="">[Code]</a> &nbsp;   
            <a href="javascript:hideshow(document.getElementById('OpenPCDet'))"> [Bibtex] </a> &nbsp; 
            <a href="https://github.com/open-mmlab/OpenPCDet"><img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/open-mmlab/OpenPCDet?style=social" /> </a> 
        <br />
        </div>
    </td>
</tr>
</table>
<!-- <pre><p id="OpenPCDet" style="font:18px; display:none">
@inproceedings{shi2020pcdet,
  title={OpenPCDet: An Open-source Toolbox for 3D Object Detection from Point Cloud},
  author={Shi, Shaoshuai and Guo, Chaoxu and Li, Hongsheng},
  Journal ={https://github.com/open-mmlab/OpenPCDet},
  year={2020}
}
</p></pre> -->
<pre><p id="OpenPCDet" style="font:18px; display:none">
@misc{openpcdet2020,
    title={OpenPCDet: An Open-source Toolbox for 3D Object Detection from Point Clouds},
    author={OpenPCDet Development Team},
    howpublished = {\url{https://github.com/open-mmlab/OpenPCDet}},
    year={2020}
}
</p></pre>
<!-- 
## Technical Report
<hr style="margin-top:-16px;margin-bottom:10px;" />




 -->

<h2 id="publications">Publications</h2>
<hr style="margin-top:-16px;margin-bottom:10px;" />

<!-- See full list at <a href="https://scholar.google.com.hk/citations?user=DC9wzBgAAAAJ&hl=zh-CN">[Google Scholar]</a>. -->

<table class="">
<tr>
    <td width="30%" valign="top">
        <img src="content/images/st3d-min.png" width="96%" />
    </td>
    <td width="70%" valign="top">
        <div style="margin-top:0px;margin-bottom:0px;">
        <a href="https://arxiv.org/abs/2103.05346" style="">
            ST3D: Self-training for Unsupervised Domain Adaptation on 3D Object Detection
        </a>
        <br />
        <font color="#000000"> Jihan Yang*, <b>Shaoshuai Shi*</b>, Zhe Wang, Hongsheng Li, Xiaojuan Qi (*co-first authors)</font>
        <br />
        <font style="font-size:15px;"><em>
            IEEE Conference on Computer Vision and Pattern Recognition
            (CVPR), 2021. 
             </em> 
        </font>
        <br />
            <a href="https://arxiv.org/pdf/2103.05346">[PDF]</a> &nbsp; 
            <a href="javascript:hideshow(document.getElementById('ST3D'))"> [Bibtex] </a> &nbsp; 
            <a href="https://github.com/CVMI-Lab/ST3D" style="">[Code]</a> &nbsp;
        <br />
        </div>
    </td>
</tr>
</table>
<pre><p id="ST3D" style="font:18px; display:none">
@inproceedings{yang2021st3d,
  title={ST3D: Self-training for Unsupervised Domain Adaptation on 3D Object Detection},
  author={Yang, Jihan and Shi, Shaoshuai and Wang, Zhe and Li, Hongsheng and Qi, Xiaojuan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2021}
}
</p></pre>

<table class="">
<tr>
    <td width="30%" valign="top">
        <img src="content/images/back-min.png" width="96%" />
    </td>
    <td width="70%" valign="top">
        <div style="margin-top:0px;margin-bottom:0px;">
        <a href="https://arxiv.org/abs/2104.06114" style="">
            Back-tracing Representative Points for Voting-based 3D Object Detection in Point Clouds
        </a>
        <br />
        <font color="#000000"> Bowen Cheng, Lu Sheng, <b>Shaoshuai Shi</b>, Ming Yang, Dong Xu</font>
        <br />
        <font style="font-size:15px;"><em>
            IEEE Conference on Computer Vision and Pattern Recognition
            (CVPR), 2021. 
             </em> 
        </font>
        <br />
            <a href="https://arxiv.org/pdf/2104.06114">[PDF]</a> &nbsp;
            <a href="javascript:hideshow(document.getElementById('BRNet'))"> [Bibtex] </a> &nbsp; 
            <a href="https://github.com/cheng052/BRNet" style="">[Code]</a> &nbsp;
        <br />
        </div>
    </td>
</tr>
</table>
<pre><p id="BRNet" style="font:18px; display:none">
@inproceedings{cheng2021back,
  title={Back-tracing Representative Points for Voting-based 3D Object Detection in Point Clouds},
  author={Cheng, Bowen and Sheng, Lu and Shi, Shaoshuai and Yang, Ming and Xu, Dong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8963--8972},
  year={2021}
}
</p></pre>

<table class="">
<tr>
    <td width="30%" valign="top">
        <img src="content/images/PVRCNN_v2_min.png" width="96%" height="120" />
    </td>
    <td width="70%" valign="top">
        <div style="margin-top:0px;margin-bottom:0px;">
        <a href="https://arxiv.org/abs/2102.00463" style="">
            PV-RCNN++: Point-Voxel Feature Set Abstraction With Local Vector Representation for 3D Object Detection
        </a>
        <br />
        <font color="#000000"> <b>Shaoshuai Shi</b>, Li Jiang, Jiajun Deng, Zhe Wang, Chaoxu Guo, Jianping Shi, Xiaogang Wang, Hongsheng Li</font>
        <br />
        <font style="font-size:15px;"><em>
            Technical report, arXiv:2102.00463
             </em> 
        </font>
        <br />
            <a href="https://arxiv.org/pdf/2102.00463.pdf">[PDF]</a> &nbsp;
            <a href="javascript:hideshow(document.getElementById('PVRCNN-v2'))"> [Bibtex] </a> &nbsp; 
        <br />
        </div>
    </td>
</tr>
</table>
<pre><p id="PVRCNN-v2" style="font:18px; display:none">
@article{shi2021pv,
  title={PV-RCNN++: Point-Voxel Feature Set Abstraction With Local Vector Representation for 3D Object Detection},
  author={Shi, Shaoshuai and Jiang, Li and Deng, Jiajun and Wang, Zhe and Guo, Chaoxu and Shi, Jianping and Wang, Xiaogang and Li, Hongsheng},
  journal={arXiv preprint arXiv:2102.00463},
  year={2021}
}
</p></pre>

<table class="">
<tr>
    <td width="30%" valign="top">
        <img src="content/images/VoxelRCNN_min.png" width="96%" height="100" />
    </td>
    <td width="70%" valign="top">
        <div style="margin-top:0px;margin-bottom:0px;">
        <a href="https://arxiv.org/abs/2012.15712" style="">
            Voxel R-CNN: Towards High Performance Voxel-based 3D Object Detection
        </a>
        <br />
        <font color="#000000"> Jiajun Deng, <b>Shaoshuai Shi</b>, Peiwei Li, Wengang Zhou, Yanyong Zhang, Houqiang Li</font>
        <br />
        <font style="font-size:15px;"><em>
            AAAI Conference on Artiﬁcial Intelligence (AAAI), 2021
             </em> 
        </font>
        <br />
            <a href="https://arxiv.org/pdf/2012.15712.pdf">[PDF]</a> &nbsp;
            <a href="javascript:hideshow(document.getElementById('VoxelRCNN'))"> [Bibtex] </a> &nbsp; 
            <a href="https://github.com/djiajunustc/Voxel-R-CNN" style="">[Code]</a> &nbsp; 
        <br />
        </div>
    </td>
</tr>
</table>
<pre><p id="VoxelRCNN" style="font:18px; display:none">
@article{deng2020voxel,
  title={Voxel R-CNN: Towards High Performance Voxel-based 3D Object Detection},
  author={Deng, Jiajun and Shi, Shaoshuai and Li, Peiwei and Zhou, Wengang and Zhang, Yanyong and Li, Houqiang},
  journal={arXiv preprint arXiv:2012.15712},
  year={2020}
}
</p></pre>

<table class="">
<tr>
    <td width="30%" valign="top">
        <img src="content/images/PVRCNN_waymo_min.png" width="96%" height="100" />
    </td>
    <td width="70%" valign="top">
        <div style="margin-top:0px;margin-bottom:0px;">
        <a href="https://arxiv.org/abs/2008.12599" style="">
            The Top-Performing LiDAR-only Solutions for 3D Detection / 3D Tracking / Domain Adaptation of Waymo Open Dataset Challenges
        </a>
        <br />
        <font color="#000000"> <b>Shaoshuai Shi</b>, Chaoxu Guo, Jihan Yang, Hongsheng Li</font>
        <br />
        <font style="font-size:15px;"><em>
      <!--       arXiv:1912.13192, Technical Report, 2019
            </em>  -->
            Technical report of top-performing LiDAR-only solutions to Waymo Open Dataset Challenges at
             Workshop of CVPR 2020. </em> 
        </font>
        <br />
            <a href="https://arxiv.org/pdf/2008.12599.pdf">[PDF]</a> &nbsp;
            <a href="javascript:hideshow(document.getElementById('PVRCNN-waymo'))"> [Bibtex] </a> &nbsp; 
        <a href="https://github.com/open-mmlab/OpenPCDet" style="">[Code]</a> &nbsp;   
            <a href="https://github.com/open-mmlab/OpenPCDet"><img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/open-mmlab/OpenPCDet?style=social" /> </a> 
        <br />
        <font color="#FF0000">Ranked 1st place among all LiDAR-only methods on 3D Detection, 3D Tracking, Domain Adaptation three tracks of the Waymo Open Dataset challenge.</font>
        <br />
        </div>
    </td>
</tr>
</table>
<pre><p id="PVRCNN-waymo" style="font:18px; display:none">
@article{shi2020pvwaymo,
  title={PV-RCNN: The Top-Performing LiDAR-only Solutions for 3D Detection/3D Tracking/Domain Adaptation of Waymo Open Dataset Challenges},
  author={Shi, Shaoshuai and Guo, Chaoxu and Yang, Jihan and Li, Hongsheng},
  journal={arXiv preprint arXiv:2008.12599},
  year={2020}
}
</p></pre>

<table class="">
<tr>
    <td width="30%" valign="top">
        <img src="content/images/PVRCNN_min.png" width="96%" height="100" />
    </td>
    <td width="70%" valign="top">
        <div style="margin-top:0px;margin-bottom:0px;">
        <a href="https://arxiv.org/abs/1912.13192" style="">
            PV-RCNN: Point-Voxel Feature Set Abstraction for 3D Object Detection
        </a>
        <br />
        <font color="#000000"> <b>Shaoshuai Shi</b>, Chaoxu Guo, Li Jiang, Zhe Wang, Jianping Shi, Xiaogang Wang, Hongsheng Li</font>
        <br />
        <font style="font-size:15px;"><em>
      <!--       arXiv:1912.13192, Technical Report, 2019
            </em>  -->
            IEEE Conference on Computer Vision and Pattern Recognition
            (CVPR), 2020. </em> 
        </font>
        <br />
            <a href="https://arxiv.org/pdf/1912.13192.pdf">[PDF]</a> &nbsp;
            <a href="javascript:hideshow(document.getElementById('PVRCNN'))"> [Bibtex] </a> &nbsp; 
	    <a href="https://github.com/open-mmlab/OpenPCDet" style="">[Code]</a> &nbsp;   
            <a href="https://github.com/open-mmlab/OpenPCDet"><img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/open-mmlab/OpenPCDet?style=social" /> </a> 
            <a href="https://github.com/sshaoshuai/PV-RCNN"><img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/sshaoshuai/PV-RCNN?style=social" /> </a>
        <br />
        <font color="#FF0000">Ranked 1st place on KITTI 3D object detection benchmark (Car, Nov-16 2019).</font>
        <br />
        </div>
    </td>
</tr>
</table>
<pre><p id="PVRCNN" style="font:18px; display:none">
@inproceedings{shi2020pv,
  title={Pv-rcnn: Point-voxel feature set abstraction for 3d object detection},
  author={Shi, Shaoshuai and Guo, Chaoxu and Jiang, Li and Wang, Zhe and Shi, Jianping and Wang, Xiaogang and Li, Hongsheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10529--10538},
  year={2020}
}
</p></pre>

<table class="">
<tr>
    <td width="30%" valign="top">
        <img src="content/images/PointGroup_min.png" width="96%" height="90" />
    </td>
    <td width="70%" valign="top">
        <div style="margin-top:0px;margin-bottom:0px;">
        <a href="https://arxiv.org/abs/2004.01658" style="">
        PointGroup: Dual-Set Point Grouping for 3D Instance Segmentation
        </a>
        <br />
        <font color="#000000">
            Li Jiang, Hengshuang Zhao, <b>Shaoshuai Shi</b>, Shu Liu, Chi-Wing Fu, Jiaya Jia
        </font>
        <br />
        <font style="font-size:15px;"><em>
            IEEE Conference on Computer Vision and Pattern Recognition 
            (CVPR), <span style="color:red;">Oral Presentation</span>, 2020. </em>
        </font>
        <br />
            <a href="https://arxiv.org/pdf/2004.01658.pdf" style="">[PDF]</a> &nbsp;
            <a href="javascript:hideshow(document.getElementById('PointGroup'))"> [Bibtex] </a> &nbsp;
        <a href="https://github.com/Jia-Research-Lab/PointGroup" style="">[Code]</a> &nbsp;   
            <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/Jia-Research-Lab/PointGroup?style=social" />
        <br />
        <font color="#FF0000">Ranked 1st place on ScanNet 3D Semantic instance benchmark (Nov-16 2019).</font>
        </div>
    </td>
</tr>
</table>
<pre><p id="PointGroup" style="font:18px; display:none">
@inproceedings{jiang2020pointgroup,
  title={PointGroup: Dual-Set Point Grouping for 3D Instance Segmentation},
  author={Jiang, Li and Zhao, Hengshuang and Shi, Shaoshuai and Liu, Shu and Fu, Chi-Wing and Jia, Jiaya},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4867--4876},
  year={2020}
}
</p></pre>

<table class="">
<tr>
    <td width="30%" valign="top">
        <img src="content/images/PartA2_v2_min.png" width="96%" />
    </td>
    <td width="70%" valign="top">
        <div style="margin-top:0px;margin-bottom:0px;">
        <a href="https://arxiv.org/abs/1907.03670" style="">
            From Points to Parts: 3D Object Detection from Point Cloud with Part-aware and Part-aggregation Network
        </a>
        <br />
        <font color="#000000"> <b>Shaoshuai Shi</b>, Zhe Wang, Jianping Shi, Xiaogang Wang, Hongsheng Li</font>
        <br />
        <font style="font-size:15px;"><i>
            IEEE Transactions on Pattern Analysis and Machine Intelligence  
            (T-PAMI), accepted. </i>
        </font>
        <br />
            <a href="https://arxiv.org/pdf/1907.03670.pdf">[PDF]</a> &nbsp;
            <a href="javascript:hideshow(document.getElementById('PartA2'))"> [Bibtex] </a> &nbsp;  
            <a href="https://github.com/open-mmlab/OpenPCDet" style="">[Code]</a> &nbsp; 
            <a href="https://github.com/open-mmlab/OpenPCDet"><img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/open-mmlab/OpenPCDet?style=social" /> </a> 
            <a href="https://github.com/sshaoshuai/PartA2-Net"><img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/sshaoshuai/PartA2-Net?style=social" /> </a>
        <br />
        <font color="#FF0000">Ranked 1st place on KITTI 3D object detection benchmark (Car, July-9 2019).</font>
        </div>
    </td>
</tr>
</table>
<pre><p id="PartA2" style="font:18px; display:none">
@article{shi2020part,
    title={From Points to Parts: 3D Object Detection from Point Cloud with Part-aware and Part-aggregation Network},
    author={Shi, Shaoshuai and Wang, Zhe and Shi, Jianping and Wang, Xiaogang and Li, Hongsheng},
    journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
    publisher={IEEE},
    year={2020}
}
</p></pre>

<table class="">
<tr>
    <td width="30%" valign="top">
        <img src="content/images/PointRCNN_min.png" width="96%" height="90" />
    </td>
    <td width="70%" valign="top">
        <div style="margin-top:0px;margin-bottom:0px;">
        <a href="https://arxiv.org/abs/1812.04244" style="">
        PointRCNN: 3D Object Proposal Generation and Detection from Point Cloud
        </a>
        <br />
        <font color="#000000"> <b>Shaoshuai Shi</b>, Xiaogang Wang, Hongsheng Li</font>
        <br />
        <font style="font-size:15px;"><em>
            IEEE Conference on Computer Vision and Pattern Recognition
            (CVPR), 2019. </em> 
        </font>
        <br />
            <a href="https://arxiv.org/pdf/1812.04244.pdf" style="">[PDF]</a> &nbsp;
            <a href="javascript:hideshow(document.getElementById('PointRCNN'))"> [Bibtex] </a> &nbsp;
            <a href="https://github.com/sshaoshuai/PointRCNN" style="">[Code]</a> &nbsp;
            <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/sshaoshuai/PointRCNN?style=social" />
        <br />
        <font color="#FF0000">The top-10 cited papers among all CVPR-2019 papers (March, 2021), refer to <a href="https://www.paperdigest.org/2021/03/most-influential-cvpr-papers-2021-03/" style="">here</a>.</font>
        </div>
    </td>
</tr>
</table>
<pre><p id="PointRCNN" style="font:18px; display:none">
@inproceedings{shi2019pointrcnn,
  title={PointRCNN: 3d Object Proposal Generation and Detection from Point Cloud},
  author={Shi, Shaoshuai and Wang, Xiaogang and Li, Hongsheng},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={770--779},
  year={2019}
}
</p></pre>

<table class="">
<tr>
    <td width="30%" align="middle" valign="top">
        <img src="content/images/ICRA2020-min.png" width="99%" height="100" />
    </td>
    <td width="70%" valign="top">
        <div style="margin-top:0px;margin-bottom:0px;">
        <a href="https://arxiv.org/abs/2002.05316" style="">
        SegVoxelNet: Exploring Semantic Context and Depth-aware Features for 3D Vehicle Detection from Point Cloud
        </a>
        <br />
        <font color="#000000">
            Hongwei Yi, <b>Shaoshuai Shi</b>, Mingyu Ding, Jiankai Sun, Kui Xu, Hui Zhou, Zhe Wang, Sheng Li, Guoping Wang
        </font>
        <br />
        <font style="font-size:15px;"><em>
            International Conference on Robotics and Automation (ICRA),  2020.</em> 
        </font>
        <br />
        <a href="https://arxiv.org/pdf/2002.05316.pdf" style="">[PDF]</a> &nbsp;
        <a href="javascript:hideshow(document.getElementById('ICRA2020'))"> [Bibtex] </a> &nbsp;
        </div>
    </td>
</tr>
</table>
<pre><p id="ICRA2020" style="font:18px; display:none">
@article{yi2020segvoxelnet,
  title={SegVoxelNet: Exploring Semantic Context and Depth-aware Features for 3D Vehicle Detection from Point Cloud},
  author={Yi, Hongwei and Shi, Shaoshuai and Ding, Mingyu and Sun, Jiankai and Xu, Kui and Zhou, Hui and Wang, Zhe and Li, Sheng and Wang, Guoping},
  journal={arXiv preprint  arXiv:2002.05316},
  year={2020}
}
</p></pre>

<table class="">
<tr>
    <td width="30%" align="middle" valign="top">
        <img src="content/images/ICLR_min.png" width="99%" height="80" />
    </td>
    <td width="70%" valign="top">
        <div style="margin-top:0px;margin-bottom:0px;">
        <a href="https://arxiv.org/abs/1903.11851" style="">
        Feature Intertwiner for Object Detection
        </a>
        <br />
        <font color="#000000">
            Hongyang Li, Bo Dai, <b>Shaoshuai Shi</b>, Wanli Ouyang, Xiaogang Wang
        </font>
        <br />
        <font style="font-size:15px;"><em>
            International Conference on Learning Representation 
            (ICLR), 2019.</em> 
        </font>
        <br />
        <a href="https://arxiv.org/pdf/1903.11851.pdf" style="">[PDF]</a> &nbsp;
        <a href="javascript:hideshow(document.getElementById('ICLR2019'))"> [Bibtex] </a> &nbsp;
        </div>
    </td>
</tr>
</table>
<pre><p id="ICLR2019" style="font:18px; display:none">
@inproceedings{li2018feature,
    title={Feature Intertwiner for Object Detection},
    author={Hongyang Li and Bo Dai and Shaoshuai Shi and Wanli Ouyang and Xiaogang Wang},
    booktitle={International Conference on Learning Representations},
    year={2019},
    url={https://openreview.net/forum?id=SyxZJn05YX},
}
</p></pre>

<table class="">
<tr>
    <td width="30%" align="middle" valign="top">
        <img src="content/images/GAL_demo.png" width="95%" height="80" />
    </td>
    <td width="70%" valign="top">
        <div style="margin-top:0px;margin-bottom:0px;">
        <a href="https://eccv2018.org/openaccess/content_ECCV_2018/papers/Li_Jiang_GAL_Geometric_Adversarial_ECCV_2018_paper.pdf" style="">
        GAL: Geometric Adversarial Loss for Single-View 3D-Object Reconstruction
        </a>
        <br />
        <font color="#000000">
            Li Jiang, <b>Shaoshuai Shi</b>, Xiaojuan Qi, Jiaya Jia
        </font>
        <br />
        <font style="font-size:15px;"><em>
            European Conference on Computer Vision 
            (ECCV), <span style="color:red;">Oral Presentation</span>, 2018. </em> 
        </font>
        <br />
        <a href="https://eccv2018.org/openaccess/content_ECCV_2018/papers/Li_Jiang_GAL_Geometric_Adversarial_ECCV_2018_paper.pdf" style="">[PDF]</a> &nbsp;
        <a href="javascript:hideshow(document.getElementById('GAL'))"> [Bibtex] </a> &nbsp;
        </div>
    </td>
</tr>
</table>
<pre><p id="GAL" style="font:18px; display:none">
@inproceedings{jiang2018gal,
    title={Gal: Geometric adversarial loss for single-view 3d-object reconstruction},
    author={Jiang, Li and Shi, Shaoshuai and Qi, Xiaojuan and Jia, Jiaya},
    booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
    pages={802--816},
    year={2018}
}
</p></pre>

<table class="">
<tr>
    <td width="30%" align="middle" valign="top">
        <img src="content/images/FCCM_min.png" width="95%" height="110" />
    </td>
    <td width="70%" valign="top">
        <div style="margin-top:0px;margin-bottom:0 px;">
        <a href="http://cadlab.cs.ucla.edu/beta/cadlab/sites/default/files/publications/fccm2017.pdf" style="">
        FP-DNN: An automated framework for mapping deep neural networks onto FPGAs with RTL-HLS hybrid templates
        </a>
        <br />
        <font color="#000000">
            Yijin Guan, Hao Liang, Ningyi Xu, Wenqiang Wang, <b>Shaoshuai Shi</b>, Xi Chen, Guangyu Sun, Wei Zhang, Jason Cong
        </font>
        <br />
        <font style="font-size:15px;"><em>
            IEEE Field-Programmable Custom Computing Machines
            (FCCM), 2017.  </em> 
        </font>
        <br />
        <a href="http://cadlab.cs.ucla.edu/beta/cadlab/sites/default/files/publications/fccm2017.pdf" style="">[PDF]</a> &nbsp;
        <a href="javascript:hideshow(document.getElementById('FCCM'))"> [Bibtex] </a> &nbsp;
        </div>
        
    </td>
</tr>
</table>
<pre><p id="FCCM" style="font:18px; display:none">
@inproceedings{guan2017fp,
    title={FP-DNN: An automated framework for mapping deep neural networks onto FPGAs with RTL-HLS hybrid templates},
    author={Guan, Yijin and Liang, Hao and Xu, Ningyi and Wang, Wenqiang and Shi, Shaoshuai and Chen, Xi and Sun, Guangyu and Zhang, Wei and Cong, Jason},
    booktitle={2017 IEEE 25th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM)},
    pages={152--159},
    year={2017},
    organization={IEEE}
}
</p></pre>

<h2 id="invited-talks">Invited Talks</h2>
<hr style="margin-top:-16px;margin-bottom:10px;" />

<ul>
  <li>[2020-06-24] VALSE Webinar: Deep Learning on Point Clouds for 3D Object Detection. <a href="https://www.bilibili.com/video/BV15K411H7wf?from=search&amp;seid=2278904913441168463">[Link (Chinese)]</a></li>
  <li>[2020-06-16] PV-RCNN: The Top-Performing LiDAR-only Solutions for 3D Detection / 3D Tracking / Domain Challenges of Waymo Open Dataset Challenges. <a href="https://sites.google.com/view/cvpr20-scalability/archived-talks/challenges">[Link]</a></li>
</ul>

<h2 id="education--experiences">Education &amp; Experiences</h2>
<hr style="margin-top:-16px;margin-bottom:10px;" />

<ul>
  <li>[Aug 2017 ~ Exp. 2021] PhD student in computer vision and deep learning at The Chinese University of Hong Kong.</li>
  <li>[July 2016 ~ July 2017] Research intern at the System Group of Microsoft Research Asia (MSRA), Beijing, China.</li>
  <li>[Aug 2013 ~ July 2017] Bachelor degree at Harbin Institute Technology, major in Computer Science and Technology.</li>
</ul>

<h2 id="honors--awards">Honors &amp; Awards</h2>
<hr style="margin-top:-16px;margin-bottom:10px;" />

<ul>
  <li><a href="https://www.worldaic.com.cn/newsdetail?uuid=0577d6d5c6f449abb8a4f7426f5d17da">World Artificial Intelligence Conference (WAIC)</a> Rising Star Award, 2021.</li>
  <li><a href="https://ai.googleblog.com/2020/10/announcing-2020-google-phd-fellows.html">Google PhD Fellowship</a> in machine perception (10 selected world-wide), 2020.</li>
  <li><a href="https://cerg1.ugc.edu.hk/hkpfs/index.html">Hong Kong PhD Fellowship</a> (The highest scholarship for PhD students in Hong Kong), 2017-2021</li>
  <li>National Scholarship, 2014, 2015, 2016</li>
  <li>Silver Prize of <a href="https://ccpc.io/post/91">China Collegiate Programming Contest (CCPC 2015)</a>, 2015</li>
  <li>Second Prize of <a href="http://en.mcm.edu.cn/">China Undergraduate Mathematical Contest in Modeling (CUMCM 2015)</a>, 2015</li>
  <li>Gold Prize of <a href="https://ccpc.io/">China Collegiate Programming Contest (CCPC) of Northeast Area</a>, 2015</li>
  <li>First Prize of Mathematical Modeling Contest of Northeast Area, 2015</li>
  <li>First Class Scholarship of HIT (six times at each semester), 2014-2016</li>
</ul>
<hr />

<div style="margin:10px auto;height: 150px; pointer-events: none;">
<!-- <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?d=dna1gh75RFxuLTLMZdN7u5SSyiCEmnOtvSjR75TKtTQ&cl=ffffff&w=a"></script> -->
<!-- <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=b8b8b8&w=300&t=n&d=dna1gh75RFxuLTLMZdN7u5SSyiCEmnOtvSjR75TKtTQ&co=ffffff&cmo=fc1a0b&cmn=21c983&ct=827d7d"></script> -->
<script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=1daeff&amp;w=320&amp;t=tt&amp;d=dna1gh75RFxuLTLMZdN7u5SSyiCEmnOtvSjR75TKtTQ&amp;ct=858585&amp;co=ffffff&amp;cmn=1bff1b"></script>
<!-- <a href="https://clustrmaps.com/site/1apwn" title="Visit tracker"><img src="//clustrmaps.com/map_v2.png?cl=59bdf5&w=300&t=tt&d=dna1gh75RFxuLTLMZdN7u5SSyiCEmnOtvSjR75TKtTQ&co=ffffff&ct=b8b3b3" /></a> -->
</div>
<p><br /></p>

    </div>
  </body>
</html>